{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "vgg16_keras_demo.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srodney/diffimageml/blob/main/diffimageml/examples/vgg16_keras_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ds7N6ZWOvtkI"
      },
      "source": [
        "## Demo of the keras vgg16 implementation\n",
        "\n",
        "ML warmup: shows a demo classification of cats and dogs images from imagenet db.  See, for example: \n",
        "\n",
        "https://www.kaggle.com/shaochuanwang/keras-warm-up-cats-vs-dogs-cnn-with-vgg16\n",
        "\n",
        "https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-to-classify-photos-of-dogs-and-cats/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNZo0-3k4Ud0"
      },
      "source": [
        "## Get the data from Kaggle to Colab\n",
        "\n",
        "To set up the training data on Google Colab, do the following:\n",
        "1. log in to Kaggle (register for an account if needed)\n",
        "2. Visit the Dogs vs Cats competition: https://www.kaggle.com/c/dogs-vs-cats/data\n",
        "3. accept the competition rules (you must do this before you can download the data using the API)\n",
        "4. Follow the steps described here: https://www.kaggle.com/general/74235"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDBCbMr4vtkO"
      },
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxmCXqxHBLUs"
      },
      "source": [
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXEBlyLKvtkP"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvQS_BKNCEo2"
      },
      "source": [
        "## Set up the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F70HeTN6vtkQ",
        "outputId": "cb5c528a-9a24-4e14-f7b3-966404cca026"
      },
      "source": [
        "# NOTE: data must be downloaded and unzipped into these directories.\n",
        "# training and validation data are labeled.  Test data are not.\n",
        "# Assumes classes are defined by subdirs within.\n",
        "traindatadir = \"dogs_vs_cats_data/train/\"\n",
        "validatedatadir = \"dogs_vs_cats_data/validate/\"\n",
        "testdatadir = \"dogs_vs_cats_data/test1/\"\n",
        "assert(os.path.isdir(traindatadir))\n",
        "assert(os.path.isdir(validatedatadir))\n",
        "assert(os.path.isdir(testdatadir))\n",
        "\n",
        "Ntrain = len(glob.glob(os.path.join(traindatadir,\"*/*jpg\")))\n",
        "Nvalidate = len(glob.glob(os.path.join(validatedatadir,\"*/*jpg\")))\n",
        "Ntest = len(glob.glob(os.path.join(testdatadir,\"*jpg\")))\n",
        "print(f\"found {Ntrain} images for training, {Nvalidate} for validation, {Ntest} for blind testing\")"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "found 20000 images for training, 5000 for validation, 12500 for blind testing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTXL_y-_CRLE",
        "outputId": "330b12aa-e683-473e-89a1-df79e7bd4735",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "datagen = ImageDataGenerator()\n",
        "traindata = datagen.flow_from_directory(directory=traindatadir,target_size=(224,224))"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 20000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "buRhND9BHOgL",
        "outputId": "ac2f6a9f-01f0-4573-d553-9777f75ffc05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "validatedata = datagen.flow_from_directory(directory=validatedatadir,target_size=(224,224))"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 5000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKNULc_IvtkQ"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(units=4096,activation=\"relu\"))\n",
        "model.add(Dense(units=4096,activation=\"relu\"))\n",
        "model.add(Dense(units=2, activation=\"softmax\"))\n"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akfJWphFvtkR",
        "outputId": "35678926-a19c-45de-8bbd-87c8ae25cacd"
      },
      "source": [
        "opt = Adam(lr=0.001)\n",
        "model.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_26 (Conv2D)           (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "conv2d_27 (Conv2D)           (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_28 (Conv2D)           (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "conv2d_29 (Conv2D)           (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_30 (Conv2D)           (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "conv2d_32 (Conv2D)           (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_33 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "conv2d_34 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_35 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_36 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_37 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "conv2d_38 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 2)                 8194      \n",
            "=================================================================\n",
            "Total params: 134,268,738\n",
            "Trainable params: 134,268,738\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BahgVgOkvtkR",
        "outputId": "d58091b7-8de7-4e84-9551-b1369b740d02"
      },
      "source": [
        "checkpoint = ModelCheckpoint(\"vgg16_1.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
        "early = EarlyStopping(monitor='val_acc', min_delta=0, patience=20, verbose=1, mode='auto')\n",
        "hist = model.fit_generator(steps_per_epoch=100,generator=traindata, validation_data= validatedata, validation_steps=10,epochs=100,callbacks=[checkpoint,early])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "  4/100 [>.............................] - ETA: 1:37:21 - loss: 3165.9537 - accuracy: 0.4694"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLK2Eo7ovtkR"
      },
      "source": [
        "plt.plot(hist.history[\"acc\"])\n",
        "plt.plot(hist.history['val_acc'])\n",
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title(\"model accuracy\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.legend([\"Accuracy\",\"Validation Accuracy\",\"loss\",\"Validation Loss\"])\n",
        "#plt.savefig(\"trainvalid.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VG1ISBO2xxdw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}