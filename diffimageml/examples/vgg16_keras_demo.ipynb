{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "vgg16_keras_demo.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srodney/diffimageml/blob/main/diffimageml/examples/vgg16_keras_demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ds7N6ZWOvtkI"
      },
      "source": [
        "## Demo of the keras vgg16 implementation\n",
        "\n",
        "ML warmup: shows a demo classification of cats and dogs images from imagenet db.  See, for example: \n",
        "\n",
        "https://www.kaggle.com/shaochuanwang/keras-warm-up-cats-vs-dogs-cnn-with-vgg16\n",
        "\n",
        "https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-to-classify-photos-of-dogs-and-cats/\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDBCbMr4vtkO"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "import glob\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import zipfile\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxmCXqxHBLUs"
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.optimizers import SGD\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dropout\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXEBlyLKvtkP"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNZo0-3k4Ud0"
      },
      "source": [
        "# Get the example image data\n",
        "\n",
        "## Option 1: from Google Drive (default)\n",
        "\n",
        "Grab the pre-fetched Kaggle zip file from a public Google Drive link.\n",
        "\n",
        "See the \"Fetch and set up the Data\" section below\n",
        "\n",
        "\n",
        "## Option 2: Get the data directly from Kaggle to Colab\n",
        "\n",
        "To get the training data directly from Kaggle to Google Colab, do the following:\n",
        "1. log in to Kaggle (register for an account if needed)\n",
        "2. Visit the Dogs vs Cats competition: https://www.kaggle.com/c/dogs-vs-cats/data\n",
        "3. accept the competition rules (you must do this before you can download the data using the API)\n",
        "4. Follow the steps described here: https://www.kaggle.com/general/74235"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jvQS_BKNCEo2"
      },
      "source": [
        "## Fetch and set up the data\n",
        "\n",
        "Here we download a zip file with the example training/validation and test data from Google Drive, unpack it, sort the data into subdirs by class, and load it into keras data generator objects."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sq_WWBfpeVeN",
        "outputId": "70eef1ae-6129-47f3-a7a5-31fef0333d54"
      },
      "source": [
        "# Grab the pre-fetched data from Google Drive\n",
        "# Gets placed into /content/dogs-vs-cats.zip\n",
        "zipfilename = \"/content/dogs-vs-cats.zip\"\n",
        "if os.path.isfile(zipfilename):\n",
        "  os.remove(zipfilename)\n",
        "!gdown --id 1xXZYJZkOzajQpHLPUvw9LzUq-zYIqbKa\n",
        "\n",
        "print(f\"Got zip file? {os.path.exists(zipfilename)}\")\n",
        "print(f\"File size = {os.stat(zipfilename).st_size} bytes\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1xXZYJZkOzajQpHLPUvw9LzUq-zYIqbKa\n",
            "To: /content/dogs-vs-cats.zip\n",
            "852MB [00:11, 74.6MB/s]\n",
            "Got zip file? True\n",
            "File size = 851576689 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IReGFQUgRge",
        "outputId": "c7701b41-03b4-4886-e05c-42675cca2c54"
      },
      "source": [
        "# unzip the top-level zip file into a local Colab data directory\n",
        "datadir = \"dogs_vs_cats_data\"\n",
        "\n",
        "with zipfile.ZipFile(zipfilename, 'r') as zip_ref:\n",
        "    zip_ref.extractall(datadir)\n",
        "\n",
        "# unzip the training/validation data : unpacks into a directory labeled 'train'\n",
        "trainzipfilepath = os.path.join(datadir, \"train.zip\")\n",
        "with zipfile.ZipFile(trainzipfilepath, 'r') as zip_ref:\n",
        "    zip_ref.extractall(datadir)\n",
        " \n",
        "traindatadir = os.path.join(datadir, \"train\")\n",
        "\n",
        "assert(os.path.exists(traindatadir))\n",
        "print(f\"Unpacked training data into {os.path.abspath(traindatadir)}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unpacked training data into /content/dogs_vs_cats_data/train\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G5P6YcSOyaTz",
        "outputId": "3b3f619a-fc7e-4517-f89c-0e26c1ba7136"
      },
      "source": [
        "imagelist = glob.glob(traindatadir + '/*jpg')\n",
        "print(f\"Total Number of images = {len(imagelist)}\")\n",
        "\n",
        "# Sort the data into two sub-directories based on class\n",
        "classnames = [\"cat\", \"dog\"]\n",
        "for classname in classnames:\n",
        "  classdir = os.path.join(traindatadir, classname)\n",
        "  if not os.path.isdir(classdir):\n",
        "    os.mkdir(classdir)\n",
        "  classfilelist = glob.glob(traindatadir + f'/{classname}*jpg')\n",
        "  print(f\"Number of {classname} images = {len(classfilelist)}\")\n",
        "  for filename in classfilelist:\n",
        "    shutil.move(filename, classdir)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Number of images = 25000\n",
            "Number of cat images = 12500\n",
            "Number of dog images = 12500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxMCySx4D_B3"
      },
      "source": [
        "# Set up the Data Generators\n",
        "\n",
        "Construct a data generator for training and validation, with an 80/20 split.\n",
        "\n",
        "Options below to adjust the image target image size, and to use image augmentation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_61lbBbpyP9R",
        "outputId": "f82f64e3-198a-4bb9-ac5d-9dd598865880"
      },
      "source": [
        "imagesize = 200 # pixels - fixing to square image arrays\n",
        "use_augmentation = False # set to true to include shifts and flip\n",
        "valsplit = 0.2  # fraction of available training data to use for validation\n",
        "\n",
        "# Create the data generator, with or without augmentation\n",
        "if use_augmentation:\n",
        "  datagen = ImageDataGenerator(rescale=1.0/255.0, width_shift_range=0.1, \n",
        "                               height_shift_range=0.1, horizontal_flip=True, \n",
        "                               validation_split=valsplit)\n",
        "else:    \n",
        "  datagen = ImageDataGenerator(rescale=1.0/255.0, validation_split=valsplit)\n",
        "\n",
        "\n",
        "print('Training data set (80%):')\n",
        "train_it = datagen.flow_from_directory(\n",
        "    directory=traindatadir, class_mode='binary', batch_size=64, \n",
        "    target_size=(imagesize, imagesize), subset='training')    \n",
        "\n",
        "print('\\n Validation data set (20%):')   \n",
        "test_it = datagen.flow_from_directory(\n",
        "    directory=traindatadir, class_mode='binary', batch_size=64, \n",
        "    target_size=(imagesize, imagesize), subset='validation')\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training data set (80%):\n",
            "Found 20000 images belonging to 2 classes.\n",
            "\n",
            " Validation data set (20%):\n",
            "Found 5000 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkut9Lh93rtP"
      },
      "source": [
        "# Define Models\n",
        "\n",
        "These functions define three different CNNs:  a one-block, a two-block, and the VGG16 model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zn13D0rP3079"
      },
      "source": [
        "# define cnn model\n",
        "def define_model_1():\n",
        "    ##One Block CNN\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(imagesize, imagesize, 3)))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    # compile model\n",
        "    opt = SGD(lr=0.001, momentum=0.9)\n",
        "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        " \n",
        "def define_model_1_dropout():\n",
        "    model = Sequential()\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(imagesize, imagesize, 3)))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    opt = SGD(lr=0.001, momentum=0.9)\n",
        "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "    \n",
        "def define_model_2():\n",
        "    \n",
        "    #Two Block CNN\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(imagesize, imagesize, 3)))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "    model.add(MaxPooling2D((2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    # compile model\n",
        "    opt = SGD(lr=0.001, momentum=0.9)\n",
        "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "    \n",
        "def VGG16():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(input_shape=(imagesize,imagesize,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),name='vgg16'))\n",
        "    model.add(Flatten(name='flatten'))\n",
        "    model.add(Dense(256, activation='relu', name='fc1'))\n",
        "    model.add(Dense(128, activation='relu', name='fc2'))\n",
        "    model.add(Dense(1, activation='sigmoid', name='output'))\n",
        "    opt = SGD(lr=0.001, momentum=0.9)\n",
        "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaoUeXKc4xQN"
      },
      "source": [
        "# plot diagnostic learning curves\n",
        "def summarize_diagnostics(history):\n",
        "    # plot loss\n",
        "    pyplot.subplot(211)\n",
        "    pyplot.title('Cross Entropy Loss')\n",
        "    pyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "    pyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "    # plot accuracy\n",
        "    pyplot.subplot(212)\n",
        "    pyplot.title('Classification Accuracy')\n",
        "    pyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "    pyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "    pyplot.legend()\n",
        "    # save plot to file\n",
        "    filename = sys.argv[0].split('/')[-1]\n",
        "    pyplot.savefig(filename + '_plot.png')\n",
        "    pyplot.close()\n",
        "\n",
        "\n",
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "    # define model\n",
        "    model = define_model_2()\n",
        "\n",
        "    # fit model\n",
        "    history = model.fit_generator(train_it, steps_per_epoch=len(train_it),\n",
        "        validation_data=test_it, validation_steps=len(test_it), epochs=30, verbose=1)\n",
        "    # evaluate model\n",
        "    _, acc = model.evaluate_generator(test_it, steps=len(test_it), verbose=0)\n",
        "    print('> %.3f' % (acc * 100.0))\n",
        "    # learning curves\n",
        "    summarize_diagnostics(history)\n",
        "    \n",
        "    model.save('final_model.h5')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f6l3P4KE4x_-"
      },
      "source": [
        "# Run the model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "X4Ollq6U3-vj",
        "outputId": "d5422c4b-dcc6-43d0-9426-936337ce8181"
      },
      "source": [
        "run_test_harness()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "313/313 [==============================] - 84s 244ms/step - loss: 0.7036 - accuracy: 0.5457 - val_loss: 0.6278 - val_accuracy: 0.6410\n",
            "Epoch 2/30\n",
            "313/313 [==============================] - 76s 242ms/step - loss: 0.6318 - accuracy: 0.6320 - val_loss: 0.6133 - val_accuracy: 0.6518\n",
            "Epoch 3/30\n",
            "313/313 [==============================] - 75s 240ms/step - loss: 0.6016 - accuracy: 0.6678 - val_loss: 0.5725 - val_accuracy: 0.6996\n",
            "Epoch 4/30\n",
            "313/313 [==============================] - 76s 242ms/step - loss: 0.5575 - accuracy: 0.7137 - val_loss: 0.5552 - val_accuracy: 0.7072\n",
            "Epoch 5/30\n",
            "313/313 [==============================] - 76s 242ms/step - loss: 0.5191 - accuracy: 0.7429 - val_loss: 0.5394 - val_accuracy: 0.7202\n",
            "Epoch 6/30\n",
            "313/313 [==============================] - 75s 239ms/step - loss: 0.4816 - accuracy: 0.7707 - val_loss: 0.5082 - val_accuracy: 0.7486\n",
            "Epoch 7/30\n",
            "313/313 [==============================] - 76s 241ms/step - loss: 0.4470 - accuracy: 0.7856 - val_loss: 0.5140 - val_accuracy: 0.7478\n",
            "Epoch 8/30\n",
            "313/313 [==============================] - 75s 240ms/step - loss: 0.4092 - accuracy: 0.8155 - val_loss: 0.4999 - val_accuracy: 0.7536\n",
            "Epoch 9/30\n",
            "313/313 [==============================] - 75s 240ms/step - loss: 0.3798 - accuracy: 0.8344 - val_loss: 0.4917 - val_accuracy: 0.7600\n",
            "Epoch 10/30\n",
            "313/313 [==============================] - 75s 241ms/step - loss: 0.3505 - accuracy: 0.8484 - val_loss: 0.5019 - val_accuracy: 0.7660\n",
            "Epoch 11/30\n",
            "313/313 [==============================] - 76s 244ms/step - loss: 0.3089 - accuracy: 0.8685 - val_loss: 0.5042 - val_accuracy: 0.7660\n",
            "Epoch 12/30\n",
            "313/313 [==============================] - 77s 245ms/step - loss: 0.2864 - accuracy: 0.8830 - val_loss: 0.5288 - val_accuracy: 0.7646\n",
            "Epoch 13/30\n",
            "313/313 [==============================] - 76s 241ms/step - loss: 0.2510 - accuracy: 0.8995 - val_loss: 0.5906 - val_accuracy: 0.7418\n",
            "Epoch 14/30\n",
            "313/313 [==============================] - 76s 243ms/step - loss: 0.2259 - accuracy: 0.9148 - val_loss: 0.5483 - val_accuracy: 0.7656\n",
            "Epoch 15/30\n",
            "313/313 [==============================] - 77s 245ms/step - loss: 0.1939 - accuracy: 0.9290 - val_loss: 0.5803 - val_accuracy: 0.7664\n",
            "Epoch 16/30\n",
            "313/313 [==============================] - 77s 245ms/step - loss: 0.1582 - accuracy: 0.9477 - val_loss: 0.7027 - val_accuracy: 0.7354\n",
            "Epoch 17/30\n",
            "313/313 [==============================] - 76s 243ms/step - loss: 0.1448 - accuracy: 0.9518 - val_loss: 0.6255 - val_accuracy: 0.7654\n",
            "Epoch 18/30\n",
            "313/313 [==============================] - 77s 245ms/step - loss: 0.1121 - accuracy: 0.9689 - val_loss: 0.6726 - val_accuracy: 0.7610\n",
            "Epoch 19/30\n",
            "313/313 [==============================] - 77s 245ms/step - loss: 0.0859 - accuracy: 0.9808 - val_loss: 0.7061 - val_accuracy: 0.7648\n",
            "Epoch 20/30\n",
            "313/313 [==============================] - 77s 246ms/step - loss: 0.0765 - accuracy: 0.9825 - val_loss: 0.7317 - val_accuracy: 0.7706\n",
            "Epoch 21/30\n",
            "313/313 [==============================] - 77s 244ms/step - loss: 0.0610 - accuracy: 0.9866 - val_loss: 0.7855 - val_accuracy: 0.7650\n",
            "Epoch 22/30\n",
            "313/313 [==============================] - 76s 243ms/step - loss: 0.0418 - accuracy: 0.9954 - val_loss: 0.8023 - val_accuracy: 0.7644\n",
            "Epoch 23/30\n",
            "313/313 [==============================] - 76s 243ms/step - loss: 0.0325 - accuracy: 0.9963 - val_loss: 0.8314 - val_accuracy: 0.7670\n",
            "Epoch 24/30\n",
            "313/313 [==============================] - 75s 240ms/step - loss: 0.0261 - accuracy: 0.9983 - val_loss: 0.8760 - val_accuracy: 0.7682\n",
            "Epoch 25/30\n",
            "313/313 [==============================] - 75s 239ms/step - loss: 0.0207 - accuracy: 0.9988 - val_loss: 0.8989 - val_accuracy: 0.7686\n",
            "Epoch 26/30\n",
            "313/313 [==============================] - 75s 239ms/step - loss: 0.0151 - accuracy: 0.9994 - val_loss: 0.9373 - val_accuracy: 0.7646\n",
            "Epoch 27/30\n",
            "313/313 [==============================] - 75s 239ms/step - loss: 0.0144 - accuracy: 0.9997 - val_loss: 0.9614 - val_accuracy: 0.7646\n",
            "Epoch 28/30\n",
            "313/313 [==============================] - 75s 241ms/step - loss: 0.0102 - accuracy: 0.9998 - val_loss: 0.9800 - val_accuracy: 0.7672\n",
            "Epoch 29/30\n",
            "313/313 [==============================] - 75s 240ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.0013 - val_accuracy: 0.7668\n",
            "Epoch 30/30\n",
            "313/313 [==============================] - 75s 240ms/step - loss: 0.0072 - accuracy: 0.9999 - val_loss: 1.0331 - val_accuracy: 0.7656\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1877: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "> 76.560\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-c1b3612b5def>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_test_harness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-54197dd6916e>\u001b[0m in \u001b[0;36mrun_test_harness\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'> %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# learning curves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0msummarize_diagnostics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'final_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-10-54197dd6916e>\u001b[0m in \u001b[0;36msummarize_diagnostics\u001b[0;34m(history)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msummarize_diagnostics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# plot loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m211\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cross Entropy Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpyplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'blue'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pyplot' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dq5myS5Kti6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}